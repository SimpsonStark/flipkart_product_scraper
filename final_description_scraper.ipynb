{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pyautogui\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('cat food 1.html')\n",
    "soup = BeautifulSoup(f.read(),'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.findAll('a', attrs = {'class' : '_2cLu-l'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_container = []\n",
    "for link in links:\n",
    "    link_url = link['href']\n",
    "    links_container.append(link_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=80.0.3987.122)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-52f48a7160af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"window.scrollTo(0, 800)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mshow_more_btn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'button[class=\"_2AkmmA uSQV49\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mshow_more_btn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    634\u001b[0m         return self.execute(command, {\n\u001b[0;32m    635\u001b[0m             \u001b[1;34m'script'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             'args': converted_args})['value']\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=80.0.3987.122)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    f = open(f'cat food {i}.html')\n",
    "    soup = BeautifulSoup(f.read(),'html.parser')\n",
    "\n",
    "    links = soup.findAll('a', attrs = {'class' : '_2cLu-l'})\n",
    "\n",
    "    #collecting links\n",
    "    counter = 0\n",
    "    links_container = []\n",
    "    for link in links:\n",
    "        link_url = link['href']\n",
    "        links_container.append(link_url)\n",
    "        \n",
    "\n",
    "    #automated scraping \n",
    "    driver = selenium.webdriver.PhantomJS()\n",
    "    for links in links_container:\n",
    "        try:\n",
    "            driver.get(links)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(10)\n",
    "            driver.get(links)\n",
    "            \n",
    "            \n",
    "        driver.execute_script(\"window.scrollTo(0, 800)\") \n",
    "        show_more_btn = driver.find_element_by_css_selector('button[class=\"_2AkmmA uSQV49\"]')\n",
    "        show_more_btn.click()\n",
    "        result = requests.get(links)\n",
    "        soup = BeautifulSoup(result.content, 'html.parser')\n",
    "        description_container = soup.findAll('div', attrs = {'class' : '_1y9a40'})\n",
    "        for descriptions in description_container:\n",
    "            description = descriptions.find('div', attrs = {'class' : '_3la3Fn _1zZOAc'})\n",
    "            with open('dog_collar_des.csv','a', newline = \"\") as f:\n",
    "                if description:\n",
    "                    f.write(f'{counter}' + ',' + description.text.replace(',',\"\") + '\\n')\n",
    "                else:\n",
    "                    f.write('NA' + '\\n')\n",
    "              \n",
    "#             print(description.find('div', attrs = {'class' : '_1oCqc9'}).text)\n",
    "#             print(description.find('div', attrs = {'class' : '_3la3Fn _1zZOAc'}).text)\n",
    "        specification_container = soup.find('div', attrs = {'class' : 'MocXoX'})\n",
    "        containers = specification_container.findAll('div', attrs = {'class' : '_2RngUh'})\n",
    "        with open('dog_collar_spec.csv','a', newline = \"\") as f:\n",
    "            for container in containers:\n",
    "                for tables in container.findAll('table'):\n",
    "                    for table in tables:\n",
    "                        for rows in table.findAll('tr', attrs = {'class' : '_3_6Uyw row'}):\n",
    "                            for columns in rows.findAll('td', attrs = {'class' : '_3-wDH3 col col-3-12'}):\n",
    "                                for child in rows.findAll('td', attrs = {'class' : '_2k4JXJ col col-9-12'}):\n",
    "                                    f.write(child.text.replace(',',\"\") + ',') \n",
    "            f.write('\\n')\n",
    "\n",
    "        counter += 1\n",
    "        print(counter, end = \" \") \n",
    "        time.sleep(10)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'C:\\\\Users\\\\mcc\\\\Downloads\\\\Dog Bowl\\\\dog_bowl.html')\n",
    "soup = BeautifulSoup(f.read(),'html.parser')\n",
    "\n",
    "links = soup.findAll('a', attrs = {'class' : '_2cLu-l'})\n",
    "\n",
    "#collecting links\n",
    "counter = 0\n",
    "links_container = []\n",
    "for link in links:\n",
    "    link_url = link['href']\n",
    "    links_container.append(link_url)\n",
    "        \n",
    "\n",
    "#automated scraping \n",
    "driver = selenium.webdriver.Chrome()\n",
    "for links in links_container[32:]:\n",
    "    try:\n",
    "        driver.get(links)\n",
    "            \n",
    "    except:\n",
    "        time.sleep(10)\n",
    "        driver.get(links)\n",
    "            \n",
    "            \n",
    "    driver.execute_script(\"window.scrollTo(0, 800)\")\n",
    "    try:\n",
    "        show_more_btn = driver.find_element_by_css_selector('button[class=\"_2AkmmA uSQV49\"]')\n",
    "        show_more_btn.click()\n",
    "    except:\n",
    "        pass\n",
    "    result = requests.get(links)\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    description_container = soup.findAll('div', attrs = {'class' : '_1y9a40'})\n",
    "    for descriptions in description_container:\n",
    "        description = descriptions.find('div', attrs = {'class' : '_3la3Fn _1zZOAc'})\n",
    "        with open('dog_bowl_des.csv','a', newline = \"\") as f:\n",
    "            try:\n",
    "                if description:\n",
    "                    f.write(f'{counter}' + ',' + description.text.replace(',',\"\") + '\\n')\n",
    "                else:\n",
    "                    f.write('NA' + '\\n')\n",
    "            except:\n",
    "                f.write(f'{counter}' + ',' + '\\n')\n",
    "              \n",
    "#             print(description.find('div', attrs = {'class' : '_1oCqc9'}).text)\n",
    "#             print(description.find('div', attrs = {'class' : '_3la3Fn _1zZOAc'}).text)\n",
    "    specification_container = soup.find('div', attrs = {'class' : 'MocXoX'})\n",
    "    containers = specification_container.findAll('div', attrs = {'class' : '_2RngUh'})\n",
    "    with open('dog_bowl_spec.csv','a', newline = \"\") as f:\n",
    "        for container in containers:\n",
    "            for tables in container.findAll('table'):\n",
    "                for table in tables:\n",
    "                    for rows in table.findAll('tr', attrs = {'class' : '_3_6Uyw row'}):\n",
    "                        for columns in rows.findAll('td', attrs = {'class' : '_3-wDH3 col col-3-12'}):\n",
    "                            for child in rows.findAll('td', attrs = {'class' : '_2k4JXJ col col-9-12'}):\n",
    "                                f.write(child.text.replace(',',\"\") + ',') \n",
    "        f.write('\\n')\n",
    "\n",
    "    counter += 1\n",
    "    print(counter, end = \" \") \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 "
     ]
    }
   ],
   "source": [
    "f = open('C:\\\\Users\\\\mcc\\\\Downloads\\\\dog grooming\\\\pet diaper.html', encoding = 'utf-8')\n",
    "soup = BeautifulSoup(f.read(),'html.parser')\n",
    "\n",
    "links = soup.findAll('a', attrs = {'class' : '_2cLu-l'})\n",
    "\n",
    "#collecting links\n",
    "counter = 0\n",
    "links_container = []\n",
    "for link in links:\n",
    "    link_url = link['href']\n",
    "    links_container.append(link_url)\n",
    "        \n",
    "\n",
    "#automated scraping \n",
    "driver = selenium.webdriver.PhantomJS()\n",
    "for links in links_container:\n",
    "    try:\n",
    "        driver.get(links)\n",
    "            \n",
    "    except:\n",
    "        time.sleep(5)\n",
    "        driver.get(links)\n",
    "            \n",
    "            \n",
    "#     driver.execute_script(\"window.scrollTo(0, 800)\")\n",
    "    try:\n",
    "        show_more_btn = driver.find_element_by_css_selector('button[class=\"_2AkmmA uSQV49\"]')\n",
    "        show_more_btn.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    result = requests.get(links)\n",
    "    with open('pet diaper_decr.csv', 'a', newline = \"\", encoding = 'utf-8') as f:\n",
    "        soup = BeautifulSoup(result.content, 'html.parser')\n",
    "        description_container = soup.findAll('div', attrs = {'class' : '_1y9a40'})\n",
    "        for descriptions in description_container:\n",
    "            description = descriptions.find('div', attrs = {'class' : '_3la3Fn _1zZOAc'})\n",
    "            if description == None:\n",
    "                description_final = 'Na'\n",
    "            else:\n",
    "                description_nocomma = (description.text.replace(',',''))\n",
    "                description_final = description_nocomma.replace('\\n','<br>').strip()\n",
    "            f.write(f'{counter}' + ',' +  description_final + '\\n')\n",
    "            \n",
    "            \n",
    "          \n",
    "    \n",
    "    with open('pet diaper_spec.csv','a', newline = \"\", encoding = 'utf-8') as f:\n",
    "        specification_container = soup.find('div', attrs = {'class' : 'MocXoX'})\n",
    "        if specification_container == None:\n",
    "            f.write('Na')\n",
    "        else:\n",
    "            containers = specification_container.findAll('div', attrs = {'class' : '_2RngUh'})\n",
    "            for container in containers:\n",
    "                for tables in container.findAll('table'):\n",
    "                    for table in tables:\n",
    "                        for rows in table.findAll('tr', attrs = {'class' : '_3_6Uyw row'}):\n",
    "                            for columns in rows.findAll('td', attrs = {'class' : '_3-wDH3 col col-3-12'}):\n",
    "                                for child in rows.findAll('td', attrs = {'class' : '_2k4JXJ col col-9-12'}):\n",
    "                                    f.write(child.text.replace(',',\"\") + ',') \n",
    "        f.write('\\n')\n",
    "    counter += 1\n",
    "    print(counter, end = \" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
